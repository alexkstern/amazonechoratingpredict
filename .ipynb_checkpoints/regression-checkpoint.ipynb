{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7f129c1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e045bd6",
   "metadata": {},
   "source": [
    "# Openai embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "7407ac1c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       [0.006420237943530083, -0.0034434357658028603,...\n",
       "1       [-0.013516747392714024, 0.013427401892840862, ...\n",
       "2       [-0.005110813304781914, -0.0019843303598463535...\n",
       "3       [-0.01380288228392601, -0.006777149625122547, ...\n",
       "4       [0.0034719263203442097, -0.005105964373797178,...\n",
       "                              ...                        \n",
       "4995    [-0.01762218214571476, 0.0030267485417425632, ...\n",
       "4996    [0.012827948667109013, 0.007280903868377209, 0...\n",
       "4997    [-0.003466191468760371, -0.005143802147358656,...\n",
       "4998    [-0.010686701163649559, -0.004436171147972345,...\n",
       "4999    [-0.008222557604312897, 0.00519371684640646, 0...\n",
       "Name: ada_embedding, Length: 5000, dtype: object"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_sample=pd.read_csv('embeddings\\sample_embed_reviews.csv')\n",
    "df_sample['ada_embedding']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c4116e25",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'numpy.ndarray'>\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Convert string representations to actual lists\n",
    "df_sample['ada_embedding'] = df_sample['ada_embedding'].apply(eval)\n",
    "\n",
    "# Convert lists to numpy arrays\n",
    "df_sample['ada_embedding'] = df_sample['ada_embedding'].apply(np.array)\n",
    "\n",
    "# Check the type of the first element\n",
    "print(type(df_sample['ada_embedding'][0]))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f10870e",
   "metadata": {},
   "source": [
    "Split training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "66af00c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "\n",
    "# Convert embeddings from 'ada_embedding' column into a matrix\n",
    "X = pd.DataFrame(df_sample['ada_embedding'].tolist())\n",
    "\n",
    "# Ratings will be our target variable\n",
    "y = df_sample['Rating out of 5']\n",
    "\n",
    "# Split data into training and testing sets (80% train, 20% test)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09256ff6",
   "metadata": {},
   "source": [
    "Linear regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "dc939d96",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Squared Error on Test Set: 0.76\n",
      "R^2 Score on Test Set: 0.60\n"
     ]
    }
   ],
   "source": [
    "# Initialize and train the linear regression model\n",
    "model = LinearRegression()\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Predict ratings on the test set\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Round the predictions to the nearest integer\n",
    "#y_pred_rounded = np.round(y_pred)\n",
    "\n",
    "# Calculate and print the Mean Squared Error and R^2 score\n",
    "mse = mean_squared_error(y_test, y_pred_rounded)\n",
    "r2 = r2_score(y_test, y_pred_rounded)\n",
    "print(f\"Mean Squared Error on Test Set: {mse:.2f}\")\n",
    "print(f\"R^2 Score on Test Set: {r2:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "51e67d25",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest - Mean Squared Error: 0.59\n",
      "Random Forest - R^2 Score: 0.69\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "# Initialize and train the Random Forest regressor\n",
    "rf_model = RandomForestRegressor(n_estimators=100, random_state=42)\n",
    "rf_model.fit(X_train, y_train)\n",
    "\n",
    "# Predict ratings on the test set\n",
    "y_pred_rf = rf_model.predict(X_test)\n",
    "\n",
    "# Round the predictions to the nearest integer\n",
    "y_pred_rf_rounded = np.round(y_pred_rf)\n",
    "\n",
    "# Calculate and print the Mean Squared Error and R^2 score for Random Forest\n",
    "mse_rf = mean_squared_error(y_test, y_pred_rf_rounded)\n",
    "r2_rf = r2_score(y_test, y_pred_rf_rounded)\n",
    "print(f\"Random Forest - Mean Squared Error: {mse_rf:.2f}\")\n",
    "print(f\"Random Forest - R^2 Score: {r2_rf:.2f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b21bcf6a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient Boosting - Mean Squared Error: 0.60\n",
      "Gradient Boosting - R^2 Score: 0.69\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "\n",
    "# Initialize and train the Gradient Boosting regressor\n",
    "gb_model = GradientBoostingRegressor(n_estimators=100, random_state=42)\n",
    "gb_model.fit(X_train, y_train)\n",
    "\n",
    "# Predict ratings on the test set\n",
    "y_pred_gb = gb_model.predict(X_test)\n",
    "\n",
    "# Round the predictions to the nearest integer\n",
    "y_pred_gb_rounded = np.round(y_pred_gb)\n",
    "\n",
    "# Calculate and print the Mean Squared Error and R^2 score for Gradient Boosting\n",
    "mse_gb = mean_squared_error(y_test, y_pred_gb_rounded)\n",
    "r2_gb = r2_score(y_test, y_pred_gb_rounded)\n",
    "print(f\"Gradient Boosting - Mean Squared Error: {mse_gb:.2f}\")\n",
    "print(f\"Gradient Boosting - R^2 Score: {r2_gb:.2f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9195d94",
   "metadata": {},
   "source": [
    "## SamLowe/roberta-base-go_emotions vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "c77f187e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       [-0.13822508, 0.36220664, 0.18394026, -1.37426...\n",
       "1       [-0.36201224, 0.303088, 0.6120266, -0.43149918...\n",
       "2       [-0.6366607, -0.291785, -0.531185, 0.9993306, ...\n",
       "3       [-0.10473046, 0.3729394, 0.032148384, -1.40663...\n",
       "4       [-0.24714077, 0.44666904, 0.093679264, -1.0492...\n",
       "                              ...                        \n",
       "4959    [-0.6513957, 0.28241706, -0.30915982, -0.61445...\n",
       "4960    [-0.20475331, -0.3199976, 0.28622904, 0.145005...\n",
       "4961    [0.23070091, 0.40976372, 1.0399045, -0.5402973...\n",
       "4962    [-1.0490204, -0.41698897, -0.51496446, 0.40294...\n",
       "4963    [-0.87713504, -0.017068934, -0.24450362, 0.403...\n",
       "Name: embedding, Length: 4964, dtype: object"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_sample_roberta_go_emotions=pd.read_csv('embeddings\\sample_embed_roberta_base_go_emotions_reviews.csv')\n",
    "df_sample_roberta_go_emotions['embedding']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "942b8b07",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'numpy.ndarray'>\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Convert string representations to actual lists\n",
    "df_sample_roberta_go_emotions['embedding'] = df_sample_roberta_go_emotions['embedding'].apply(eval)\n",
    "\n",
    "# Convert lists to numpy arrays\n",
    "df_sample_roberta_go_emotions['embedding'] = df_sample_roberta_go_emotions['embedding'].apply(np.array)\n",
    "\n",
    "# Check the type of the first element\n",
    "print(type(df_sample_roberta_go_emotions['embedding'][0]))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75acbba5",
   "metadata": {},
   "source": [
    "Split training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "1fab86c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "\n",
    "# Assuming df_sample is already loaded with embeddings in 'embedding' column\n",
    "# and ratings in 'Rating out of 5' column\n",
    "\n",
    "# Convert embeddings from 'embedding' column into a matrix\n",
    "X_ = pd.DataFrame(df_sample_roberta_go_emotions['embedding'] .tolist())\n",
    "\n",
    "# Ratings will be our target variable\n",
    "y_ = df_sample_roberta_go_emotions['Rating out of 5']\n",
    "\n",
    "# Split data into training and testing sets (80% train, 20% test)\n",
    "X_train_, X_test_, y_train_, y_test_ = train_test_split(X_, y_, test_size=0.2, random_state=42)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b74232ea",
   "metadata": {},
   "source": [
    "Linear regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "3fa0fab6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Squared Error on Test Set: 0.89\n",
      "R^2 Score on Test Set: 0.60\n"
     ]
    }
   ],
   "source": [
    "# Initialize and train the linear regression model\n",
    "model = LinearRegression()\n",
    "model.fit(X_train_, y_train_)\n",
    "\n",
    "# Predict ratings on the test set\n",
    "y_pred_ = model.predict(X_test_)\n",
    "\n",
    "# Round the predictions to the nearest integer\n",
    "y_pred_rounded_ = np.round(y_pred_)\n",
    "\n",
    "# Calculate and print the Mean Squared Error and R^2 score\n",
    "mse = mean_squared_error(y_test_, y_pred_rounded_)\n",
    "r2_ = r2_score(y_test_, y_pred_rounded_)\n",
    "print(f\"Mean Squared Error on Test Set: {mse:.2f}\")\n",
    "print(f\"R^2 Score on Test Set: {r2:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d71ae66",
   "metadata": {},
   "source": [
    "Random Forest regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "2f6b31a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest - Mean Squared Error: 0.77\n",
      "Random Forest - R^2 Score: 0.61\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "# Initialize and train the Random Forest regressor\n",
    "rf_model_ = RandomForestRegressor(n_estimators=100, random_state=42)\n",
    "rf_model_.fit(X_train_, y_train_)\n",
    "\n",
    "# Predict ratings on the test set\n",
    "y_pred_rf = rf_model_.predict(X_test_)\n",
    "\n",
    "# Round the predictions to the nearest integer\n",
    "y_pred_rf_rounded = np.round(y_pred_rf)\n",
    "\n",
    "# Calculate and print the Mean Squared Error and R^2 score for Random Forest\n",
    "mse_rf = mean_squared_error(y_test_, y_pred_rf_rounded)\n",
    "r2_rf = r2_score(y_test_, y_pred_rf_rounded)\n",
    "print(f\"Random Forest - Mean Squared Error: {mse_rf:.2f}\")\n",
    "print(f\"Random Forest - R^2 Score: {r2_rf:.2f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dab8f7b8",
   "metadata": {},
   "source": [
    "Gradient Boosting regressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "50ca9b8c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient Boosting - Mean Squared Error: 0.85\n",
      "Gradient Boosting - R^2 Score: 0.58\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "# Initialize and train the Gradient Boosting regressor\n",
    "gb_model = GradientBoostingRegressor(n_estimators=100, random_state=42)\n",
    "gb_model.fit(X_train_, y_train_)\n",
    "\n",
    "# Predict ratings on the test set\n",
    "y_pred_gb = gb_model.predict(X_test_)\n",
    "\n",
    "# Round the predictions to the nearest integer\n",
    "y_pred_gb_rounded = np.round(y_pred_gb)\n",
    "\n",
    "# Calculate and print the Mean Squared Error and R^2 score for Gradient Boosting\n",
    "mse_gb = mean_squared_error(y_test_, y_pred_gb_rounded)\n",
    "r2_gb = r2_score(y_test_, y_pred_gb_rounded)\n",
    "print(f\"Gradient Boosting - Mean Squared Error: {mse_gb:.2f}\")\n",
    "print(f\"Gradient Boosting - R^2 Score: {r2_gb:.2f}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b654f38",
   "metadata": {},
   "source": [
    "## SamLowe/roberta-base vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "e4ebdd01",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       [-0.077856794, 0.09048438, -0.022385973, -0.10...\n",
       "1       [-0.06333335, 0.09018205, -0.044614114, -0.153...\n",
       "2       [-0.12731871, 0.1091575, -0.030448508, -0.1625...\n",
       "3       [-0.06350201, 0.06525059, -0.026214935, -0.104...\n",
       "4       [-0.06970922, 0.08771731, -0.020580553, -0.107...\n",
       "                              ...                        \n",
       "4959    [-0.09142549, 0.1281499, -0.037414804, -0.1301...\n",
       "4960    [-0.06628171, 0.112053216, -0.0050543044, -0.1...\n",
       "4961    [-0.09986623, 0.129924, -0.0419501, -0.1332095...\n",
       "4962    [-0.09662871, 0.114080794, -0.047377393, -0.10...\n",
       "4963    [-0.12147999, 0.114735596, -0.026296899, -0.13...\n",
       "Name: embedding, Length: 4964, dtype: object"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_sample_roberta_=pd.read_csv('embeddings\\sample_embed_roberta_base_reviews.csv')\n",
    "df_sample_roberta_['embedding']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "deb94ecf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'numpy.ndarray'>\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Convert string representations to actual lists\n",
    "df_sample_roberta_['embedding'] = df_sample_roberta_['embedding'].apply(eval)\n",
    "\n",
    "# Convert lists to numpy arrays\n",
    "df_sample_roberta_['embedding'] = df_sample_roberta_['embedding'].apply(np.array)\n",
    "\n",
    "# Check the type of the first element\n",
    "print(type(df_sample_roberta_['embedding'][0]))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d87ad07",
   "metadata": {},
   "source": [
    "Split training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "9f690dfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "\n",
    "# Assuming df_sample is already loaded with embeddings in 'embedding' column\n",
    "# and ratings in 'Rating out of 5' column\n",
    "\n",
    "# Convert embeddings from 'embedding' column into a matrix\n",
    "X_ = pd.DataFrame(df_sample_roberta_['embedding'] .tolist())\n",
    "\n",
    "# Ratings will be our target variable\n",
    "y_ = df_sample_roberta_['Rating out of 5']\n",
    "\n",
    "# Split data into training and testing sets (80% train, 20% test)\n",
    "X_train_, X_test_, y_train_, y_test_ = train_test_split(X_, y_, test_size=0.2, random_state=42)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10eabe81",
   "metadata": {},
   "source": [
    "Linear regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "43e2c963",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Squared Error on Test Set: 0.84\n",
      "R^2 Score on Test Set: 0.60\n"
     ]
    }
   ],
   "source": [
    "# Initialize and train the linear regression model\n",
    "model = LinearRegression()\n",
    "model.fit(X_train_, y_train_)\n",
    "\n",
    "# Predict ratings on the test set\n",
    "y_pred_ = model.predict(X_test_)\n",
    "\n",
    "# Round the predictions to the nearest integer\n",
    "y_pred_rounded_ = np.round(y_pred_)\n",
    "\n",
    "# Calculate and print the Mean Squared Error and R^2 score\n",
    "mse = mean_squared_error(y_test_, y_pred_rounded_)\n",
    "r2_ = r2_score(y_test_, y_pred_rounded_)\n",
    "print(f\"Mean Squared Error on Test Set: {mse:.2f}\")\n",
    "print(f\"R^2 Score on Test Set: {r2:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43aee249",
   "metadata": {},
   "source": [
    "Random forest regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "c748739f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest - Mean Squared Error: 0.95\n",
      "Random Forest - R^2 Score: 0.53\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "# Initialize and train the Random Forest regressor\n",
    "rf_model_ = RandomForestRegressor(n_estimators=100, random_state=42)\n",
    "rf_model_.fit(X_train_, y_train_)\n",
    "\n",
    "# Predict ratings on the test set\n",
    "y_pred_rf = rf_model_.predict(X_test_)\n",
    "\n",
    "# Round the predictions to the nearest integer\n",
    "y_pred_rf_rounded = np.round(y_pred_rf)\n",
    "\n",
    "# Calculate and print the Mean Squared Error and R^2 score for Random Forest\n",
    "mse_rf = mean_squared_error(y_test_, y_pred_rf_rounded)\n",
    "r2_rf = r2_score(y_test_, y_pred_rf_rounded)\n",
    "print(f\"Random Forest - Mean Squared Error: {mse_rf:.2f}\")\n",
    "print(f\"Random Forest - R^2 Score: {r2_rf:.2f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "6888f27c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient Boosting - Mean Squared Error: 0.87\n",
      "Gradient Boosting - R^2 Score: 0.57\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "# Initialize and train the Gradient Boosting regressor\n",
    "gb_model = GradientBoostingRegressor(n_estimators=100, random_state=42)\n",
    "gb_model.fit(X_train_, y_train_)\n",
    "\n",
    "# Predict ratings on the test set\n",
    "y_pred_gb = gb_model.predict(X_test_)\n",
    "\n",
    "# Round the predictions to the nearest integer\n",
    "y_pred_gb_rounded = np.round(y_pred_gb)\n",
    "\n",
    "# Calculate and print the Mean Squared Error and R^2 score for Gradient Boosting\n",
    "mse_gb = mean_squared_error(y_test_, y_pred_gb_rounded)\n",
    "r2_gb = r2_score(y_test_, y_pred_gb_rounded)\n",
    "print(f\"Gradient Boosting - Mean Squared Error: {mse_gb:.2f}\")\n",
    "print(f\"Gradient Boosting - R^2 Score: {r2_gb:.2f}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdb14f05",
   "metadata": {},
   "source": [
    "# Premade LiYuan/amazon-review-sentiment-analysis model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90e7a80d",
   "metadata": {},
   "source": [
    "This is an existing review sentiment analysis model that has been trained on amazon reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "c3cd44e8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f3d4c3bc45e34413afc089157389b7d5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)okenizer_config.json:   0%|          | 0.00/556 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d704cae3e15a4a46995de4a3ce35c906",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)solve/main/vocab.txt:   0%|          | 0.00/872k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e9f4ced4a95a42f1987bc233dac7f118",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)/main/tokenizer.json:   0%|          | 0.00/2.56M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b0a77e1eeaed4989ad586da5a773bd0b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)cial_tokens_map.json:   0%|          | 0.00/112 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "abb6bcc58cf64c3ebec57b73597a725c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)lve/main/config.json:   0%|          | 0.00/1.23k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "de029ccaa3d04e98ae84a3732f2b0d61",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading pytorch_model.bin:   0%|          | 0.00/670M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"LiYuan/amazon-review-sentiment-analysis\")\n",
    "\n",
    "model = AutoModelForSequenceClassification.from_pretrained(\"LiYuan/amazon-review-sentiment-analysis\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "ec263ac7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Uniq Id</th>\n",
       "      <th>Pageurl</th>\n",
       "      <th>Complete_Review</th>\n",
       "      <th>Rating out of 5</th>\n",
       "      <th>vector</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>afffe2013b28b4f315309524e70fbd0a</td>\n",
       "      <td>https://www.amazon.com/All-New-Amazon-Echo-Dot...</td>\n",
       "      <td>Four Stars. I love it!!</td>\n",
       "      <td>4.0</td>\n",
       "      <td>[0.9538168907165527, 0.041505444794893265, 0.0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>a76e8f02c13607341913a6f9621272b2</td>\n",
       "      <td>https://www.amazon.com/All-New-Amazon-Echo-Dot...</td>\n",
       "      <td>I replaced Siri with Alexa... I bought family ...</td>\n",
       "      <td>3.0</td>\n",
       "      <td>[0.7930777072906494, 0.04460990056395531, 0.21...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>95989b4f7b36af92938eb1ff8b47bf75</td>\n",
       "      <td>https://www.amazon.com/All-New-Amazon-Echo-Dot...</td>\n",
       "      <td>It was cool while it lasted. It was cool while...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>[0.0006247399724088609, 0.005567466840147972, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>f4d2291f4ee22563e68f7f84cdca3823</td>\n",
       "      <td>https://www.amazon.com/All-New-Amazon-Echo-Dot...</td>\n",
       "      <td>Love using. Second one I have.  Love using them</td>\n",
       "      <td>5.0</td>\n",
       "      <td>[0.9560614228248596, 0.05400032922625542, 0.02...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>42edfc6f411a7527e680c4f139dc14d3</td>\n",
       "      <td>https://www.amazon.com/All-New-Amazon-Echo-Dot...</td>\n",
       "      <td>Five Stars. love it</td>\n",
       "      <td>5.0</td>\n",
       "      <td>[0.9350842237472534, 0.024932313710451126, 0.0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4959</th>\n",
       "      <td>2db2237f8a732e7df9bbe3043f03042b</td>\n",
       "      <td>https://www.amazon.com/All-New-Amazon-Echo-Dot...</td>\n",
       "      <td>Not a good portable/satellite speaker, but ser...</td>\n",
       "      <td>3.0</td>\n",
       "      <td>[0.005262279883027077, 0.1664196252822876, 0.0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4960</th>\n",
       "      <td>6424dfbd428b73d882ecb59e2486ae92</td>\n",
       "      <td>https://www.amazon.com/All-New-Amazon-Echo-Dot...</td>\n",
       "      <td>Two Stars. Sound not as great for playing musi...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>[0.006110591813921928, 0.013705299235880375, 0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4961</th>\n",
       "      <td>3c42ff782a7fc594bd495869b0cefff3</td>\n",
       "      <td>https://www.amazon.com/All-New-Amazon-Echo-Dot...</td>\n",
       "      <td>do love asking Alexa for jokes. I wanted to be...</td>\n",
       "      <td>3.0</td>\n",
       "      <td>[0.9231314659118652, 0.018452603369951248, 0.0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4962</th>\n",
       "      <td>133d25ebfd7c57076c73c82661afd09c</td>\n",
       "      <td>https://www.amazon.com/All-New-Amazon-Echo-Dot...</td>\n",
       "      <td>Luckily it was free with my dish. I talk to it...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>[0.0006587005918845534, 0.007016032934188843, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4963</th>\n",
       "      <td>d2c7151da19f474a881e2523844c7717</td>\n",
       "      <td>https://www.amazon.com/All-New-Amazon-Echo-Dot...</td>\n",
       "      <td>Don't waste your money. Can't find a purpose t...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>[0.0006498440052382648, 0.0018738448852673173,...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4964 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                               Uniq Id  \\\n",
       "0     afffe2013b28b4f315309524e70fbd0a   \n",
       "1     a76e8f02c13607341913a6f9621272b2   \n",
       "2     95989b4f7b36af92938eb1ff8b47bf75   \n",
       "3     f4d2291f4ee22563e68f7f84cdca3823   \n",
       "4     42edfc6f411a7527e680c4f139dc14d3   \n",
       "...                                ...   \n",
       "4959  2db2237f8a732e7df9bbe3043f03042b   \n",
       "4960  6424dfbd428b73d882ecb59e2486ae92   \n",
       "4961  3c42ff782a7fc594bd495869b0cefff3   \n",
       "4962  133d25ebfd7c57076c73c82661afd09c   \n",
       "4963  d2c7151da19f474a881e2523844c7717   \n",
       "\n",
       "                                                Pageurl  \\\n",
       "0     https://www.amazon.com/All-New-Amazon-Echo-Dot...   \n",
       "1     https://www.amazon.com/All-New-Amazon-Echo-Dot...   \n",
       "2     https://www.amazon.com/All-New-Amazon-Echo-Dot...   \n",
       "3     https://www.amazon.com/All-New-Amazon-Echo-Dot...   \n",
       "4     https://www.amazon.com/All-New-Amazon-Echo-Dot...   \n",
       "...                                                 ...   \n",
       "4959  https://www.amazon.com/All-New-Amazon-Echo-Dot...   \n",
       "4960  https://www.amazon.com/All-New-Amazon-Echo-Dot...   \n",
       "4961  https://www.amazon.com/All-New-Amazon-Echo-Dot...   \n",
       "4962  https://www.amazon.com/All-New-Amazon-Echo-Dot...   \n",
       "4963  https://www.amazon.com/All-New-Amazon-Echo-Dot...   \n",
       "\n",
       "                                        Complete_Review  Rating out of 5  \\\n",
       "0                               Four Stars. I love it!!              4.0   \n",
       "1     I replaced Siri with Alexa... I bought family ...              3.0   \n",
       "2     It was cool while it lasted. It was cool while...              2.0   \n",
       "3       Love using. Second one I have.  Love using them              5.0   \n",
       "4                                   Five Stars. love it              5.0   \n",
       "...                                                 ...              ...   \n",
       "4959  Not a good portable/satellite speaker, but ser...              3.0   \n",
       "4960  Two Stars. Sound not as great for playing musi...              2.0   \n",
       "4961  do love asking Alexa for jokes. I wanted to be...              3.0   \n",
       "4962  Luckily it was free with my dish. I talk to it...              1.0   \n",
       "4963  Don't waste your money. Can't find a purpose t...              1.0   \n",
       "\n",
       "                                                 vector  \n",
       "0     [0.9538168907165527, 0.041505444794893265, 0.0...  \n",
       "1     [0.7930777072906494, 0.04460990056395531, 0.21...  \n",
       "2     [0.0006247399724088609, 0.005567466840147972, ...  \n",
       "3     [0.9560614228248596, 0.05400032922625542, 0.02...  \n",
       "4     [0.9350842237472534, 0.024932313710451126, 0.0...  \n",
       "...                                                 ...  \n",
       "4959  [0.005262279883027077, 0.1664196252822876, 0.0...  \n",
       "4960  [0.006110591813921928, 0.013705299235880375, 0...  \n",
       "4961  [0.9231314659118652, 0.018452603369951248, 0.0...  \n",
       "4962  [0.0006587005918845534, 0.007016032934188843, ...  \n",
       "4963  [0.0006498440052382648, 0.0018738448852673173,...  \n",
       "\n",
       "[4964 rows x 5 columns]"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_sample_roberta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "ec9c77b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
    "import numpy as np\n",
    "\n",
    "def amazon_review_classifier(review):\n",
    "    try:\n",
    "        inputs = tokenizer(review, return_tensors=\"pt\", truncation=True, max_length=512)\n",
    "        outputs = model(**inputs)\n",
    "        predicted_class = outputs.logits.argmax(dim=1).item() + 1  # Adding 1 because the model predicts numbers between 0 and 4\n",
    "        return predicted_class\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing review: {e}\")  # Optional: print the error for debugging\n",
    "        return np.nan\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "75efd833",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply the amazon_review_classifier to the reviews\n",
    "predicted_ratings = [amazon_review_classifier(review) for review in df_sample_roberta['Complete_Review']]\n",
    "\n",
    "# Extract the actual ratings for the reviews\n",
    "actual_ratings = df_sample_roberta['Rating out of 5'].tolist()\n",
    "\n",
    "# Compare the predicted and actual ratings\n",
    "comparison_df = pd.DataFrame({\n",
    "    'Actual Rating': actual_ratings,\n",
    "    'Predicted Rating': predicted_ratings\n",
    "})\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "ffab2ddd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Actual Rating</th>\n",
       "      <th>Predicted Rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4.0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3.0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5.0</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.0</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4959</th>\n",
       "      <td>3.0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4960</th>\n",
       "      <td>2.0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4961</th>\n",
       "      <td>3.0</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4962</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4963</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4964 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Actual Rating  Predicted Rating\n",
       "0               4.0                 4\n",
       "1               3.0                 3\n",
       "2               2.0                 1\n",
       "3               5.0                 5\n",
       "4               5.0                 5\n",
       "...             ...               ...\n",
       "4959            3.0                 3\n",
       "4960            2.0                 2\n",
       "4961            3.0                 5\n",
       "4962            1.0                 1\n",
       "4963            1.0                 1\n",
       "\n",
       "[4964 rows x 2 columns]"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "comparison_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "a0cb4cf6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "total_nan_values = comparison_df['Predicted Rating'].isna().sum()\n",
    "total_nan_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "8083bb1e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Actual Rating</th>\n",
       "      <th>Predicted Rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4959</th>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4960</th>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4961</th>\n",
       "      <td>3.0</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4962</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4963</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4964 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Actual Rating  Predicted Rating\n",
       "0               4.0               4.0\n",
       "1               3.0               3.0\n",
       "2               2.0               1.0\n",
       "3               5.0               5.0\n",
       "4               5.0               5.0\n",
       "...             ...               ...\n",
       "4959            3.0               3.0\n",
       "4960            2.0               2.0\n",
       "4961            3.0               5.0\n",
       "4962            1.0               1.0\n",
       "4963            1.0               1.0\n",
       "\n",
       "[4964 rows x 2 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "comparison_df['Predicted Rating'] = comparison_df['Predicted Rating'].astype(float)\n",
    "display(comparison_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "604d8d22",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 65.43%\n",
      "Mean Squared Error (MSE): 0.80\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import mean_squared_error, accuracy_score\n",
    "\n",
    "# Filter out rows with np.nan in the \"Predicted Rating\" column\n",
    "filtered_df = comparison_df.dropna(subset=['Predicted Rating'])\n",
    "\n",
    "# Calculate Accuracy\n",
    "accuracy = accuracy_score(filtered_df['Actual Rating'], filtered_df['Predicted Rating'])\n",
    "\n",
    "# Calculate Mean Squared Error (MSE)\n",
    "mse = mean_squared_error(filtered_df['Actual Rating'], filtered_df['Predicted Rating'])\n",
    "\n",
    "print(f\"Accuracy: {accuracy*100:.2f}%\")\n",
    "print(f\"Mean Squared Error (MSE): {mse:.2f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c908305",
   "metadata": {},
   "source": [
    "As we can see the model gets marginally better results that the performance of the models we have created throughout this project."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4360889",
   "metadata": {},
   "source": [
    "## MiniLM embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "f99cffad",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       [-0.037147197872400284, 0.026904301717877388, ...\n",
       "1       [-0.026737932115793228, -0.06941179931163788, ...\n",
       "2       [-0.005086897406727076, -0.0256204754114151, 0...\n",
       "3       [-0.1017942875623703, 0.027229677885770798, 0....\n",
       "4       [-0.0896272137761116, 0.019552603363990784, 0....\n",
       "                              ...                        \n",
       "4995    [0.0380321629345417, -0.035417355597019196, 0....\n",
       "4996    [-0.011440230533480644, -0.030268460512161255,...\n",
       "4997    [-0.03457475081086159, -0.07828406989574432, 0...\n",
       "4998    [-0.012026957236230373, 0.022902967408299446, ...\n",
       "4999    [-0.013014293275773525, -0.09492605179548264, ...\n",
       "Name: embedding, Length: 5000, dtype: object"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_sample_miniLM=pd.read_csv('embeddings\\sample_embed_minilm.csv')\n",
    "df_sample_miniLM['embedding']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "4e3aac2c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'numpy.ndarray'>\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Convert string representations to actual lists\n",
    "df_sample_miniLM['embedding'] = df_sample_miniLM['embedding'].apply(eval)\n",
    "\n",
    "# Convert lists to numpy arrays\n",
    "df_sample_miniLM['embedding'] = df_sample_miniLM['embedding'].apply(np.array)\n",
    "\n",
    "# Check the type of the first element\n",
    "print(type(df_sample_miniLM['embedding'][0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "766d0ad6",
   "metadata": {},
   "source": [
    "Split training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "86f30e4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "\n",
    "# Assuming df_sample is already loaded with embeddings in 'embedding' column\n",
    "# and ratings in 'Rating out of 5' column\n",
    "\n",
    "# Convert embeddings from 'embedding' column into a matrix\n",
    "X_ = pd.DataFrame(df_sample_miniLM['embedding'] .tolist())\n",
    "\n",
    "# Ratings will be our target variable\n",
    "y_ = df_sample_miniLM['Rating out of 5']\n",
    "\n",
    "# Split data into training and testing sets (80% train, 20% test)\n",
    "X_train_, X_test_, y_train_, y_test_ = train_test_split(X_, y_, test_size=0.2, random_state=42)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3276c7a0",
   "metadata": {},
   "source": [
    "Linear regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "f06df819",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Squared Error on Test Set: 0.90\n",
      "R^2 Score on Test Set: 0.60\n"
     ]
    }
   ],
   "source": [
    "# Initialize and train the linear regression model\n",
    "model = LinearRegression()\n",
    "model.fit(X_train_, y_train_)\n",
    "\n",
    "# Predict ratings on the test set\n",
    "y_pred_ = model.predict(X_test_)\n",
    "\n",
    "# Round the predictions to the nearest integer\n",
    "y_pred_rounded_ = np.round(y_pred_)\n",
    "\n",
    "# Calculate and print the Mean Squared Error and R^2 score\n",
    "mse = mean_squared_error(y_test_, y_pred_rounded_)\n",
    "r2_ = r2_score(y_test_, y_pred_rounded_)\n",
    "print(f\"Mean Squared Error on Test Set: {mse:.2f}\")\n",
    "print(f\"R^2 Score on Test Set: {r2:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26105764",
   "metadata": {},
   "source": [
    "Random forest regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "fe1b59b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest - Mean Squared Error: 0.97\n",
      "Random Forest - R^2 Score: 0.49\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "# Initialize and train the Random Forest regressor\n",
    "rf_model_ = RandomForestRegressor(n_estimators=100, random_state=42)\n",
    "rf_model_.fit(X_train_, y_train_)\n",
    "\n",
    "# Predict ratings on the test set\n",
    "y_pred_rf = rf_model_.predict(X_test_)\n",
    "\n",
    "# Round the predictions to the nearest integer\n",
    "y_pred_rf_rounded = np.round(y_pred_rf)\n",
    "\n",
    "# Calculate and print the Mean Squared Error and R^2 score for Random Forest\n",
    "mse_rf = mean_squared_error(y_test_, y_pred_rf_rounded)\n",
    "r2_rf = r2_score(y_test_, y_pred_rf_rounded)\n",
    "print(f\"Random Forest - Mean Squared Error: {mse_rf:.2f}\")\n",
    "print(f\"Random Forest - R^2 Score: {r2_rf:.2f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "068bf33b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient Boosting - Mean Squared Error: 0.95\n",
      "Gradient Boosting - R^2 Score: 0.50\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "# Initialize and train the Gradient Boosting regressor\n",
    "gb_model = GradientBoostingRegressor(n_estimators=100, random_state=42)\n",
    "gb_model.fit(X_train_, y_train_)\n",
    "\n",
    "# Predict ratings on the test set\n",
    "y_pred_gb = gb_model.predict(X_test_)\n",
    "\n",
    "# Round the predictions to the nearest integer\n",
    "y_pred_gb_rounded = np.round(y_pred_gb)\n",
    "\n",
    "# Calculate and print the Mean Squared Error and R^2 score for Gradient Boosting\n",
    "mse_gb = mean_squared_error(y_test_, y_pred_gb_rounded)\n",
    "r2_gb = r2_score(y_test_, y_pred_gb_rounded)\n",
    "print(f\"Gradient Boosting - Mean Squared Error: {mse_gb:.2f}\")\n",
    "print(f\"Gradient Boosting - R^2 Score: {r2_gb:.2f}\")\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
